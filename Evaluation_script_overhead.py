#!/usr/bin/env python
# -*- coding: utf-8 -*-

## usage python3 <first-benchmark.csv> <second-benchmark.csv>

#File take two CSV file input (format generated by the benchmark script)
#and plot Network Latency, Provenance Database Latency and 
#Pipeline Latency for the topology from the first node to the last node between the two csv 


import string
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import csv
from datetime import datetime
import uuid
import time_uuid
import re
import sys

print ('Number of arguments:', len(sys.argv), 'arguments')
print ('Argument List:', str(sys.argv))

filenames = []
filenames.append(sys.argv[1])
filenames.append(sys.argv[2])
filenames.append(sys.argv[3])
print (filenames)

columnnames = ['id', 'nodeid', 'ctime','rtime','stime','time','inputdps']


def getdatetime(x):
    x = x.strip()
    return ((time_uuid.TimeUUID(bytes=uuid.UUID(x).bytes).get_datetime()))


df_1  =  pd.read_csv(filenames[0], delimiter='|')
df_1.dropna(inplace=True)
df_1.columns = df_1.columns.str.strip()
df_1.ctime =  pd.to_datetime(df_1.ctime)
df_1.rtime = pd.to_datetime(df_1.rtime)
df_1.stime = pd.to_datetime(df_1.stime)
df_1 = df_1[columnnames]
df_1['node_latency'] = ((df_1.stime - df_1.rtime).dt.total_seconds()) * 1000
df_1.time = df_1.time.apply(getdatetime)
df_1['provenance_database_latency'] = abs((df_1.stime - df_1.time).dt.total_seconds() * 1000)

df_2  =  pd.read_csv(filenames[1], delimiter='|')
df_2.dropna(inplace=True)
df_2.columns = df_2.columns.str.strip()
df_2.ctime =  pd.to_datetime(df_2.ctime)
df_2.rtime = pd.to_datetime(df_2.rtime)
df_2.stime = pd.to_datetime(df_2.stime)
df_2 = df_2[columnnames]
df_2['node_latency'] = ((df_2.stime - df_2.rtime).dt.total_seconds()) * 1000
df_2.time = df_2.time.apply(getdatetime)
df_2['provenance_database_latency'] = abs((df_2.stime - df_2.time).dt.total_seconds() * 1000)

df_3  =  pd.read_csv(filenames[2], delimiter='|')
df_3.dropna(inplace=True)
df_3.columns = df_3.columns.str.strip()
df_3.ctime =  pd.to_datetime(df_3.ctime)
df_3.rtime = pd.to_datetime(df_3.rtime)
df_3.stime = pd.to_datetime(df_3.stime)
df_3 = df_3[columnnames]
df_3['node_latency'] = ((df_3.stime - df_3.rtime).dt.total_seconds()) * 1000
df_3.time = df_3.time.apply(getdatetime)
df_3['provenance_database_latency'] = abs((df_3.stime - df_3.time).dt.total_seconds() * 1000)

nodeidx = list(df_1.nodeid.unique())
#print (max(nodeidx)) 

plt.style.use('seaborn-darkgrid')
matplotlib.rcParams.update({'font.size': 18})

labels = []
for word in filenames:
    word =  (word.replace('Benchmark_',''))
    labels.append(word.replace('.csv',''))

# Plot histogram for Node latency
def plothist_nodelatency(a,b,c,node,f1,f2,f3):
    plt.figure(figsize=(12,10))
    plt.hist([a,b,c], alpha=1, bins=10,label=[f1,f2,f3])
    plt.title('Network Latency for Node: {}'.format(node))
    plt.legend(prop={'size': 14})
    plt.xlabel('Time / ms')
    plt.ylabel('Frequency')
    fig_name = 'Network Latency: ' + f1 + ' vs ' + f2 + ' vs ' + f3 +' for Node: ' + str(node) +'.tiff'
    plt.savefig(fig_name)
    #plt.show()
    return


def plothist_DBlatency(a,b,c,node,f1,f2,f3):
    plt.figure(figsize=(12,10))
    plt.hist([a,b,c],  alpha=1, bins=10,label=[f1,f2,f3])
    plt.title('Provenance Database Latency for Node: {}'.format(node))
    plt.xlabel('Time / ms')
    plt.ylabel('Frequency')
    plt.legend(prop={'size': 14})
    fig_name = 'Provenance Database Latency: ' + f1 + ' vs ' + f2 +  ' vs ' + f3 + ' for Node: ' + str(node)+'.tiff'
    plt.savefig(fig_name)
    #plt.show()
    return

def plot_linegraph(data,data_1, data_2,node,f1,f2,f3):
    plt.figure(figsize=(12,10))
    plt.title('Network Latency for Node: {}'.format(node))
    plt.xlabel('# of Datapoints')
    plt.ylabel('Time/ms')
    plt.plot(data,label = f1)
    plt.plot(data_1, label=f2)
    plt.plot(data_2,label=f3)
    plt.legend(prop={'size': 14})
    fig_name = 'Line Graph for Network Latency: ' + f1 + ' vs ' + f2 +  ' vs ' + f3 +' for Node: ' + str(node) +'.tiff'
    plt.savefig(fig_name)
    #plt.show()
    return

datapoints = round(df_1.shape[0] * .75)
for node in nodeidx:
    data = df_1[(df_1['nodeid'] == node)].head(datapoints).node_latency
    data_1 = df_2[(df_2['nodeid'] == node)].head(datapoints).node_latency
    data_2 = df_3[(df_3['nodeid'] == node)].head(datapoints).node_latency
    plothist_nodelatency(data,data_1,data_2,node,labels[0],labels[1],labels[2])
    
    dataP = df_1[(df_1['nodeid'] == node)].head(datapoints).provenance_database_latency
    dataP_1 = df_2[(df_2['nodeid'] == node)].head(datapoints).provenance_database_latency
    data_2 = df_3[(df_3['nodeid'] == node)].head(datapoints).node_latency
    plothist_DBlatency(data,data_1,data_2,node,labels[0],labels[1],labels[2])

datapoints = round(df_1.shape[0] * .075)
for node in nodeidx:
    data = df_1[(df_1['nodeid'] == node)].head(datapoints).node_latency
    data_1 = df_2[(df_2['nodeid'] == node)].head(datapoints).node_latency
    data_2 = df_3[(df_3['nodeid'] == node)].head(datapoints).node_latency
    plot_linegraph(data,data_1,data_2,node,labels[0],labels[1],labels[2])


def trimming(x):
    return (x.strip())


def get_rtime(v):
    #print (v)
    if (v != 'null'):
        tmp = re.findall(r'[0-9A-F]+', v, re.I)
        return list(df_1[(df_1['id'] == tmp[0]) & (df_1['nodeid'] == (max(nodeidx) - 1) )].rtime.values)
    else:
        return v

def get_rtime_2(v):
    #print (v)
    if (v != 'null'):
        tmp = re.findall(r'[0-9A-F]+', v, re.I)
        return list(df_2[(df_2['id'] == tmp[0]) & (df_2['nodeid'] == (max(nodeidx) -1) )].rtime.values)
    else:
        return v

def get_rtime_3(v):
    #print (v)
    if (v != 'null'):
        tmp = re.findall(r'[0-9A-F]+', v, re.I)
        return list(df_3[(df_3['id'] == tmp[0]) & (df_3['nodeid'] == (max(nodeidx) -1) )].rtime.values)
    else:
        return v

def getTimestamp(x):
    if (len(x) == 0):
        #print ("empty")
        return x
    else:
        return (pd.Timestamp(x[0]))

def plot_pipeline_latency(data,data_1, data_2,node,f1,f2,f3):
    plt.figure(figsize=(12,10))
    plt.title('Pipeline Latency for Endpoint Node: {}'.format(node))
    plt.xlabel('# of Datapoints')
    plt.ylabel('Time/ms')
    plt.plot(data,label = f1)
    plt.plot(data_1, label=f2)
    plt.plot(data_2,label=f3)
    plt.legend(prop={'size': 14})
    fig_name = 'Pipeline Latency for Endpoint Node: ' + f1 + ' vs ' + f2 +  ' vs ' + f3 +' for Node: ' + str(node) +'.tiff'
    plt.savefig(fig_name)
    #plt.show()
    return
datapoints = 1500
df_1.id = df_1.id.apply(trimming)
df_1.inputdps = df_1.inputdps.apply(trimming)
df_1['rtime_first'] = df_1.inputdps
df_1.rtime_first = df_1.rtime_first.apply(get_rtime)
#print (df_1.dtypes)

df_1['pipeline_latency'] = ""
data_latency = df_1[(df_1['nodeid'] == max(nodeidx))].head(datapoints)
data_latency.rtime_first.dropna(inplace=True)
data_latency = data_latency[data_latency['rtime_first'].map(lambda d: len(d)) > 0]
data_latency.rtime_first = data_latency.rtime_first.apply(getTimestamp)
#print (data_latency.dtypes)
#print (data_latency.shape)
data_latency['pipeline_latency'] = (data_latency.rtime - (data_latency.rtime_first)).dt.total_seconds() * 1000
#print (data_latency.dtypes)



df_2.id = df_2.id.apply(trimming)
df_2.inputdps = df_2.inputdps.apply(trimming)
df_2['rtime_first'] = df_2.inputdps
df_2.rtime_first = df_2.rtime_first.apply(get_rtime_2)
df_2['pipeline_latency'] = ""
data_latency_1 = df_2[(df_2['nodeid'] == max(nodeidx))].head(datapoints)
data_latency_1.rtime_first.dropna(inplace=True)
data_latency_1 = data_latency_1[data_latency_1['rtime_first'].map(lambda d: len(d)) > 0]
data_latency_1.rtime_first = data_latency_1.rtime_first.apply(getTimestamp)
data_latency_1['pipeline_latency'] = (data_latency_1.rtime - (data_latency_1.rtime_first)).dt.total_seconds() * 1000
#print (data_latency_1.dtypes)

df_3.id = df_3.id.apply(trimming)
df_3.inputdps = df_3.inputdps.apply(trimming)
df_3['rtime_first'] = df_3.inputdps
df_3.rtime_first = df_3.rtime_first.apply(get_rtime_3)
df_3['pipeline_latency'] = ""
data_latency_2 = df_3[(df_3['nodeid'] == max(nodeidx))].head(datapoints)
data_latency_2.rtime_first.dropna(inplace=True)
data_latency_2 = data_latency_2[data_latency_2['rtime_first'].map(lambda d: len(d)) > 0]
data_latency_2.rtime_first = data_latency_2.rtime_first.apply(getTimestamp)
data_latency_2['pipeline_latency'] = (data_latency_2.rtime - (data_latency_2.rtime_first)).dt.total_seconds() * 1000
#print (data_latency_2.dtypes)


plot_pipeline_latency(data_latency.pipeline_latency,data_latency_1.pipeline_latency,data_latency_2.pipeline_latency,max(nodeidx),labels[0],labels[1],labels[2])

datapoints = 3500

print ("Evaluation Complete")